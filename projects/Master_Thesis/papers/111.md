# Content
- [shortcut learning in deep neural networks](https://github.com/YHJYH/Machine_Learning/blob/main/projects/Master_Thesis/papers/shortcut_learning_in_deep_NN.md#shortcut-learning-in-deep-neural-networks)
- [ImageNet-trained CNNs are biased towards texture; Increasing shape bias improves accuracy and robustness](https://github.com/YHJYH/Machine_Learning/blob/main/projects/Master_Thesis/papers/bias_towards_texture.md#imagenet-trained-cnns-are-biased-towards-texture-increasing-shape-bias-improves-accuracy-and-robustness)
- [Adversarial Examples are not Bugs, they are Features](https://github.com/YHJYH/Machine_Learning/blob/main/projects/Master_Thesis/papers/adversarial_examples_are_features.md#adversarial-examples-are-not-bugs-they-are-features)
- [Invariant Risk Minimization](https://github.com/YHJYH/Machine_Learning/blob/main/projects/Master_Thesis/papers/IRM.md#invariant-risk-minimization)
- [Similarity of Neural Network Representations Revisited (CKA)](https://github.com/YHJYH/Machine_Learning/blob/main/projects/Master_Thesis/papers/similarity_of_NN_CKA.md#similarity-of-neural-network-representations-revisited)
- [Learning De-biased Representations with Biased Representations](https://github.com/YHJYH/Machine_Learning/blob/main/projects/Master_Thesis/papers/learn_debias.md#learning-de-biased-representations-with-biased-representations)
- [RAPID LEARNING OR FEATURE REUSE? TOWARDS UNDERSTANDING THE EFFECTIVENESS OF MAML (remove inner loop)](https://github.com/YHJYH/Machine_Learning/blob/main/projects/Master_Thesis/papers/remove_inner_loop.md#rapid-learning-or-feature-reuse-towards-understanding-the-effectiveness-of-maml)
- [The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks](https://github.com/YHJYH/Machine_Learning/blob/main/projects/Master_Thesis/papers/lottery_ticket.md#the-lottery-ticket-hypothesis-finding-sparse-trainable-neural-networks)
- [The Pitfalls of Simplicity Bias in Neural Networks](https://github.com/YHJYH/Machine_Learning/blob/main/projects/Master_Thesis/papers/pitfall.md#the-pitfalls-of-simplicity-bias-in-neural-networks)
- [Gradient Starvation: A Learning Proclivity in Neural Networks](https://github.com/YHJYH/Machine_Learning/blob/main/projects/Master_Thesis/papers/gradient_starvation.md#gradient-starvation-a-learning-proclivity-in-neural-networks)
