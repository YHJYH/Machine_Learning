# RAPID LEARNING OR FEATURE REUSE? TOWARDS UNDERSTANDING THE EFFECTIVENESS OF MAML

> CCA provides a way to the compare representations of two (latent) layers L1, L2 of a neural network, outputting a similarity score between 0 (not similar at all) and 1 (identical). <br>
> the inner loop induces little to no functional change. <br>
> remove the inner loop updates for the network body, and apply inner loop adaptation only to the head. <br>
> Computational benefit <br>

这篇文章对我而言有用的地方在于：
1. 在某个项目中介绍了CCA和CKA的用法以及绘图；
2. 介绍了某些layers的param freeze的方法；
3. 提到了降底model complexity的好处；

[back](https://github.com/YHJYH/Machine_Learning/blob/main/projects/Master_Thesis/papers/refs.md#content)
